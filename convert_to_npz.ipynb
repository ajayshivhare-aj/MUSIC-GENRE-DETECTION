{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert into npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "AUDIO_DIR = 'audio_files/fma_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tids_from_directory(audio_dir):\n",
    "    \"\"\"Get track IDs from the mp3s in a directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_dir : str\n",
    "        Path to the directory where the audio files are stored.\n",
    "    Returns\n",
    "    -------\n",
    "        A list of track IDs.\n",
    "    \"\"\"\n",
    "    tids = []\n",
    "    for _, dirnames, files in os.walk(audio_dir):\n",
    "        if dirnames == []:\n",
    "            tids.extend(int(file[:-4]) for file in files)\n",
    "    return tids\n",
    "\n",
    "\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "    Examples\n",
    "    \"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    a = os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n",
    "    a = a.replace(\"\\\\\", \"/\")\n",
    "    return a\n",
    "\n",
    "def create_spectogram(track_id):\n",
    "    filename = get_audio_path(AUDIO_DIR, track_id)\n",
    "    y, sr = librosa.load(filename)\n",
    "    spect = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=2048, hop_length=1024)\n",
    "    spect = librosa.power_to_db(spect, ref=np.max)\n",
    "    return spect.T\n",
    "\n",
    "def plot_spect(track_id):\n",
    "    spect = create_spectogram(track_id)\n",
    "    print(spect.shape)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spect.T, y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "    \n",
    "def create_array(df):\n",
    "    genres = []\n",
    "    X_spect = np.empty((0, 640, 128))\n",
    "    count = 0\n",
    "    #Code skips records in case of errors\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            count += 1\n",
    "            track_id = int(row['track_id'])\n",
    "            genre = str(row[('track', 'genre_top')])\n",
    "            spect = create_spectogram(track_id)\n",
    "\n",
    "            # Normalize for small shape differences\n",
    "            spect = spect[:640, :]\n",
    "            X_spect = np.append(X_spect, [spect], axis=0)\n",
    "            genres.append(dict_genres[genre])\n",
    "            if count % 100 == 0:\n",
    "                print(\"Currently processing: \", count)\n",
    "        except:\n",
    "            print(\"Couldn't process: \", count)\n",
    "            continue\n",
    "    y_arr = np.array(genres)\n",
    "    return X_spect, y_arr    \n",
    "\n",
    "def splitDataFrameIntoSmaller(df, chunkSize = 1600): \n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n",
    "    return listOfDf\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = get_tids_from_directory(AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset with genre and track IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">set</th>\n",
       "      <th>track</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>genre_top</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Pop</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Folk</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Folk</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               set            track track_id\n",
       "             split subset genre_top         \n",
       "track_id                                    \n",
       "2         training  small   Hip-Hop        2\n",
       "5         training  small   Hip-Hop        5\n",
       "10        training  small       Pop       10\n",
       "140       training  small      Folk      140\n",
       "141       training  small      Folk      141"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'fma_metadata/tracks.csv'\n",
    "tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "keep_cols = [('set', 'split'),\n",
    "('set', 'subset'),('track', 'genre_top')]\n",
    "\n",
    "df_all = tracks[keep_cols]\n",
    "df_all = df_all[df_all[('set', 'subset')] == 'small']\n",
    "\n",
    "df_all['track_id'] = df_all.index\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_genres = {'Electronic':1, 'Experimental':2, 'Folk':3, 'Hip-Hop':4, \n",
    "               'Instrumental':5,'International':6, 'Pop' :7, 'Rock': 8  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['training', 'validation', 'test'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[('set', 'split')].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, validation and test subsetsÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[df_all[('set', 'split')]=='training']\n",
    "df_valid = df_all[df_all[('set', 'split')]=='validation']\n",
    "df_test = df_all[df_all[('set', 'split')]=='test']\n",
    "\n",
    "df_test.to_csv(\"test_file\")\n",
    "df_test_ = pd.read_csv(\"test_file\")\n",
    "\n",
    "np.savez('test_arr', X_test, y_test)\n",
    "np.savez('valid_arr', X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Train data split into 4 chunks to do the slow pre-processing in phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "listDf = splitDataFrameIntoSmaller(df_train)\n",
    "df1_train = listDf[0]\n",
    "df2_train = listDf[1]\n",
    "df3_train = listDf[2]\n",
    "df4_train = listDf[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, y_train1 = create_array(df1_train)\n",
    "np.savez('train1_arr', X_train1, y_train1)  \n",
    "\n",
    "X_train2, y_train2 = create_array(df2_train)\n",
    "np.savez('train2_arr', X_train2, y_train2)\n",
    "\n",
    "X_train3, y_train3 = create_array(df3_train)\n",
    "np.savez('train3_arr', X_train3, y_train3)\n",
    "\n",
    "X_train4, y_train4 = create_array(df4_train)\n",
    "np.savez('train4_arr', X_train4, y_train4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('train1_arr.npz')\n",
    "X_train1 = npzfile['arr_0']\n",
    "y_train1 = npzfile['arr_1']\n",
    "\n",
    "npzfile = np.load('train2_arr.npz')\n",
    "X_train2 = npzfile['arr_0']\n",
    "y_train2 = npzfile['arr_1']\n",
    "\n",
    "npzfile = np.load('train3_arr.npz')\n",
    "X_train3 = npzfile['arr_0']\n",
    "y_train3 = npzfile['arr_1']\n",
    "\n",
    "npzfile = np.load('train4_arr.npz')\n",
    "X_train4 = npzfile['arr_0']\n",
    "y_train4 = npzfile['arr_1']\n",
    "\n",
    "npzfile = np.load('valid_arr.npz')\n",
    "X_valid = npzfile['arr_0']\n",
    "y_valid = npzfile['arr_1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train -1\n",
    "y_valid = y_valid -1\n",
    "\n",
    "np.save(\"y_train\", y_train)\n",
    "np.save(\"y_valid\", y_valid)\n",
    "\n",
    "a = librosa.core.db_to_power(X_train1, ref = 1.0)\n",
    "\n",
    "X_train_raw2 = librosa.core.db_to_power(X_train2, ref = 1.0)\n",
    "X_train_raw3 = librosa.core.db_to_power(X_train3, ref = 1.0)\n",
    "X_train_raw4 = librosa.core.db_to_power(X_train4, ref = 1.0)\n",
    "X_train_raw = np.concatenate((a, X_train_raw2), axis = 0)\n",
    "\n",
    "np.savez('X_train_raw', X_train_raw)\n",
    "X_train_raw = np.concatenate((a, X_train_raw2), axis = 0)\n",
    "np.save(\"X_train_raw3\", X_train_raw3 )\n",
    "np.save(\"X_train_raw4\", X_train_raw4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('X_train_raw.npz')\n",
    "x_train_raw1 = npzfile['arr_0']\n",
    "\n",
    "X_train_log_ = np.log(x_train_raw1)\n",
    "np.save(\"X_train_log_3200\", X_train_log_) \n",
    "\n",
    "X_train_log = np.load('X_train_log.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw_ = np.concatenate((X_train_log, X_train_log_), axis = 0)\n",
    "np.savez(\"Xtrain_123_4800\", X_train_raw_)\n",
    "\n",
    "X_train_raw4 = np.load(\"X_train_raw4.npy\")\n",
    "X_train_log1 = np.log(X_train_raw4)\n",
    "np.save(\"X_train_log1\", X_train_log1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_valid_raw = librosa.core.db_to_power(X_valid, ref=1.0)\n",
    "\n",
    "X_train_log1 = np.load(\"X_train_log1.npy\")\n",
    "\n",
    "npzfile = np.load('Xtrain_123_4800.npz')\n",
    "Xtrain_123_4800 = npzfile['arr_0']\n",
    "\n",
    "X_train_log = np.concatenate((Xtrain_123_4800 , X_train_log1), axis = 0)\n",
    "np.savez(\"X_train_log\", X_train_log)\n",
    "\n",
    "npzfile = np.load('X_train_log.npz')\n",
    "x_train_log = npzfile['arr_0']\n",
    "\n",
    "x_valid_raw = librosa.core.db_to_power(X_valid, ref = 1.0)\n",
    "x_valid_log = np.log(x_valid_raw)\n",
    "np.save(\"x_valid_log\", x_valid_log)\n",
    "\n",
    "x_valid_log = np.load(\"x_valid_log.npy\")\n",
    "\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_valid = np.load(\"y_valid.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = unison_shuffled_copies(x_train_log, y_train)\n",
    "X_valid, y_valid = unison_shuffled_copies(x_valid_log, y_valid)\n",
    "\n",
    "np.savez('shuffled_train', X_train, y_train)\n",
    "np.savez('shuffled_valid', X_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
